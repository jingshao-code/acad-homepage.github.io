---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

## üëã Hi, I'm Jing Shao.

I‚Äôm a graduate student in **Computer Software Engineering** at [**Northeastern University ‚Äì College of Engineering**](https://coe.northeastern.edu/), with hands-on experience in **machine learning**, **multi-modal model safety**, and **end-to-end AI system development**.

My research has explored **audio-based jailbreak attacks** on **LALMs**, where I analyzed model vulnerabilities and constructed adversarial audio prompts. I‚Äôve also worked on **World Models** for humanoid robot planning and the **safety evaluation of VLA systems**, focusing on their deployment in real-world environments.

In industry-facing projects, I contributed to a stealth-stage AI startup, developing **AI-powered audio systems** and integrating ML models into scalable infrastructure to support **real-time interaction**. I am also a **Google Summer of Code (GSoC) 2025** contributor, working on **secure Flutter engine integration**.

Driven by a passion for **embodied AI** and its safe real-world applications, I aim to build **human-centered, trustworthy intelligent systems**.  

## üìå I‚Äôm actively seeking **Fall 2025 internship or full-time roles** in **Machine Learning Engineering**, **Robotics**, **Applied AI**, or **Software Development**.
Feel free to reach out or connect!



# üî• News
- **May 2025** ‚Äî üéâ Awarded the **AWS re:Inforce 2025 Grant** for contributions to AI safety and open-source.

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv 2025</div><img src='images/nips.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Jailbreak-AudioBench: In-Depth Evaluation and Analysis of Jailbreak Threats for Large Audio Language Models](https://arxiv.org/abs/2501.13772)

Hao Cheng, Erjia Xiao, **Jing Shao**, Yichi Wang, Le Yang, Chao Shen, Philip Torr, Jindong Gu, Renjing Xu

<!--[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**-->

- **Academic Impact**: This work introduces Jailbreak-AudioBench, the first comprehensive benchmark for evaluating jailbreak threats against Large Audio Language Models (LALMs). It presents a unified toolbox, curated dataset, and evaluation pipeline to systematically study how audio-specific hidden semantics‚Äîsuch as tone, intonation, background noise, and emotion‚Äîcan be used to compromise model safety. This work fills a major gap in multimodal LLM security research and lays the foundation for future defense strategies.
- **Practical Impact**: This work introduces Jailbreak-AudioBench, the first comprehensive benchmark for evaluating jailbreak threats against Large Audio Language Models (LALMs). It presents a unified toolbox, curated dataset, and evaluation pipeline to systematically study how audio-specific hidden semantics‚Äîsuch as tone, intonation, background noise, and emotion‚Äîcan be used to compromise model safety. This work fills a major gap in multimodal LLM security research and lays the foundation for future defense strategies.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">MobiCom 2024</div><img src='images/mobicom.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Energy-based Active Learning for Bringing Beam-induced Domain Gap for 3D Object Detection](https://dl.acm.org/doi/abs/10.1145/3636534.3694723)

Le Yang, Yixuan Yan, **Jing Shao**, Hao Cheng, Fan Li

<!--[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**-->

- **Academic Impact**: This work proposes an energy-based active learning framework to close the domain gap between 64-beam and 16-beam LiDARs, enabling knowledge transfer with minimal labeled data.
- **Practical Impact**: Our method significantly reduces annotation cost and achieves high-performance 3D object detection on 16-beam LiDAR with only a small portion of labeled samples.
</div>
</div>


# üéñ Honors and Awards
- *May 2025* Awarded **AWS All Builders Welcome Grant** re:Inforce
- *May 2025* GSoC 2025 Contributor & **Flutter Organization Member**
- *Sep 2024* Awarded **AWS All Builders Welcome Grant** re:Invent

# üìñ Educations
- *Jan 2024 ‚Äì Apr 2026*, M.S., Computer Software Engineering, Northeastern University.

# üì£ Invited Talks
- *Jun 2025*, Attending **AWS re:Inforce 2025**, Philadelphia
- *Dec 2024*, Attending **AWS re:Invent 2024**, Las Vegas  
- *Oct 2024*, Presenting research at **MobiCom 2024**, Washington D.C. 

# üíª Internships
- *May 2025 ‚Äì Present*, [Google Summer of Code](https://summerofcode.withgoogle.com/), Software Developer.
- *Jan 2025 ‚Äì Present*, Stealth AI Startup, Machine Learning Engineer.
- *Sep 2024 ‚Äì May 2025*, [The Hong Kong University of Science and Technology](https://hkust.edu.hk), Research Assistant.
- *May 2024 ‚Äì Sep 2024*, [X-Humanoid](https://x-humanoid.com/), Machine Learning Engineer.

